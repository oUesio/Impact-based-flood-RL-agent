{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11896ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "import seaborn as sns\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b54132",
   "metadata": {},
   "source": [
    "### URBAN RURAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef215539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "urban = pd.read_csv(\"data/urban_rural.csv\")\n",
    "counts = urban['Urban_rural_flag'].value_counts()\n",
    "urban_probs = counts / counts.sum()\n",
    "p_urban = urban_probs['Urban']\n",
    "urban_sample = np.random.binomial(n=1, p=p_urban, size=1)[0]\n",
    "print(urban_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139eeedf",
   "metadata": {},
   "source": [
    "### POPULATION DENSITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e69cbb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158.97244218707326\n"
     ]
    }
   ],
   "source": [
    "popden = pd.read_csv(\"data/population_density.csv\", dtype={\"LAD2021\": \"string\", \"OA21CD\": \"string\", \"Total\": \"Int64\"})\n",
    "merged = popden.merge(urban, on=\"OA21CD\", how=\"left\")\n",
    "popden_urbanrural = merged[['LAD2021','OA21CD','Total','Urban_rural_flag']]\n",
    "\n",
    "flag = 'urban' if urban_sample == 1 else 'rural'\n",
    "total  = popden_urbanrural[popden_urbanrural[\"Urban_rural_flag\"].str.lower() == flag][\"Total\"]\n",
    "\n",
    "log = np.log(total)\n",
    "\n",
    "mu, sigma = log.mean(), log.std()\n",
    "\n",
    "popden_sample = np.random.lognormal(mean=mu, sigma=sigma, size=1)[0]\n",
    "print(popden_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e293e3",
   "metadata": {},
   "source": [
    "### DISABILITY RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d1f93de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18282935194095662\n"
     ]
    }
   ],
   "source": [
    "disability = pd.read_csv(\"data/disabled.csv\")\n",
    "total_disability = disability.groupby('Disability (3 categories)')['Observation'].sum()\n",
    "#disability_probs = total_disability / total_disability.sum()\n",
    "\n",
    "alpha = total_disability['Disabled under the Equality Act'] + 1\n",
    "beta = total_disability['Not disabled under the Equality Act'] + 1\n",
    "\n",
    "disabled_sample = np.random.beta(alpha, beta, size=1)[0]\n",
    "print(disabled_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a36ab1",
   "metadata": {},
   "source": [
    "### ENGLISH PROFICIENCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db365f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2699192 66413\n",
      "0.9761280833866088\n"
     ]
    }
   ],
   "source": [
    "def map_proficiency(category):\n",
    "    if category in [\n",
    "        \"Main language is English (English or Welsh in Wales)\",\n",
    "        \"Main language is not English (English or Welsh in Wales): Can speak English very well or well\"\n",
    "    ]:\n",
    "        return \"Good English Proficiency\"\n",
    "    elif category == \"Main language is not English (English or Welsh in Wales): Cannot speak English or cannot speak English well\":\n",
    "        return \"Bad English Proficiency\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "english = pd.read_csv(\"data/english_proficiency.csv\")   \n",
    "total_english = english.groupby('Proficiency in English language (4 categories)')['Observation'].sum()\n",
    "english['Proficiency_Group'] = english['Proficiency in English language (4 categories)'].apply(map_proficiency)\n",
    "grouped_english = english.groupby('Proficiency_Group')['Observation'].sum()\n",
    "#english_probs = grouped_english / grouped_english.sum()\n",
    "\n",
    "alpha = grouped_english['Good English Proficiency'] + 1\n",
    "beta = grouped_english['Bad English Proficiency'] + 1\n",
    "\n",
    "english_sample = np.random.beta(alpha, beta, size=1)[0]\n",
    "print(english_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4806237",
   "metadata": {},
   "source": [
    "### MEAN INCOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5830d490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39535.37691370101\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import skewnorm, lognorm\n",
    "\n",
    "income = pd.read_csv(\"data/mean_income.csv\")\n",
    "income['Total annual income (£)'] = (\n",
    "    income['Total annual income (£)']\n",
    "    .str.strip()        \n",
    "    .str.replace(',', '')      \n",
    "    .astype(float)       \n",
    ")\n",
    "\n",
    "log_income = np.log(income['Total annual income (£)'])\n",
    "shape, loc, scale = skewnorm.fit(log_income)\n",
    "sample_log = skewnorm.rvs(shape, loc=loc, scale=scale, size=1)\n",
    "income_sample = np.exp(sample_log)[0]\n",
    "print(income_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a2c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "871f82b6",
   "metadata": {},
   "source": [
    "### LOW-INCOME FRACTION (NOT DONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1220aefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23520.0\n",
      "0.1792183634234001\n",
      "0.0018787571088464375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "median = income['Total annual income (£)'].median()\n",
    "low_income_threshold = 0.6 * median\n",
    "print(low_income_threshold)\n",
    "\n",
    "variance_log_skewnorm = skewnorm.var(shape, loc=loc, scale=scale)\n",
    "\n",
    "###### PART THAT DOESNT SEEM RIGHT\n",
    "meanlog = np.log(income_sample)\n",
    "std = np.sqrt(variance_log_skewnorm)\n",
    "print(std)\n",
    "prob_low_income = lognorm.cdf(low_income_threshold, s=std, scale=np.exp(meanlog))\n",
    "print(prob_low_income)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b7efe",
   "metadata": {},
   "source": [
    "### MEAN PROPERTY VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0fd91568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172189.41832701166\n"
     ]
    }
   ],
   "source": [
    "property = pd.read_csv(\"data/property_value.csv\")\n",
    "property = property.dropna(subset=['price', 'property_type', 'duration'])\n",
    "property = property[property['price'] > 0]\n",
    "\n",
    "log_property = np.log(property['price'])\n",
    "shape, loc, scale = skewnorm.fit(log_property)\n",
    "sample_log = skewnorm.rvs(shape, loc=loc, scale=scale, size=1)\n",
    "property_sample = np.exp(sample_log)[0]\n",
    "print(property_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fb54a9",
   "metadata": {},
   "source": [
    "### DISTANCE TO WATER (DENSITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e6714bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347.9868995474528\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import gamma\n",
    "\n",
    "gdf = gpd.read_file(\"data/watercourse_density/watercourse_density.shp\")\n",
    "length = gdf[\"length_km\"]\n",
    "pct_zero = (length == 0).sum() / len(length)\n",
    "zero_sample = np.random.binomial(n=1, p=pct_zero, size=1)[0]\n",
    "\n",
    "gdf_nonzero = gdf[gdf[\"length_km\"] != 0].copy()\n",
    "length_nonzero = gdf_nonzero[\"length_km\"]\n",
    "shape, loc, scale = gamma.fit(length_nonzero)\n",
    "length_sample = 0 if zero_sample == 1 else gamma.rvs(a=shape, loc=loc, scale=scale, size=1)[0]\n",
    "print(length_sample*1000) # metres\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f42573",
   "metadata": {},
   "source": [
    "### DISTANCE TO WATER (DISTANCE) MIGHT HAVE TO CHOOSE ONE OR THE OTHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3edf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 648.2645334   125.83904867  482.52047465  623.35400269  437.18838751\n",
      "   63.01059675 1787.34533752  957.83382439  200.07151216  502.90078147]\n"
     ]
    }
   ],
   "source": [
    "gdf = gpd.read_file(\"data/watercourse_distance/watercourse_distance.shp\")\n",
    "distance = gdf[\"distance_t\"]\n",
    "shape, loc, scale = gamma.fit(distance)\n",
    "\n",
    "max_distance = distance.max()\n",
    "epsilon = 0.01\n",
    "scale_factor = max_distance / (length_sample + epsilon)\n",
    "\n",
    "distance_sample = gamma.rvs(a=shape, loc=loc, scale=scale, size=10)\n",
    "#if length_sample == 0:\n",
    "#    distance_sample = max_distance - distance_sample\n",
    "print(distance_sample) # metres\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa963e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
